{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./bert/')\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import rnn_cell_impl\n",
    "import bert\n",
    "from bert import modeling\n",
    "from bert import tokenization\n",
    "from bert.modeling import BertConfig, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOutputProjectionWrapper(tf.contrib.rnn.RNNCell):\n",
    "    \"\"\"Operator adding an output projection to the given cell.\n",
    "    Note: in many cases it may be more efficient to not use this wrapper,\n",
    "    but instead concatenate the whole sequence of your outputs in time,\n",
    "    do the projection on this batch-concatenated sequence, then split it\n",
    "    if needed or directly feed into a softmax.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cell, output_size, W, activation=None, reuse=None):\n",
    "        \"\"\"Create a cell with output projection.\n",
    "        Args:\n",
    "          cell: an RNNCell, a projection to output_size is added to it.\n",
    "          output_size: integer, the size of the output after projection.\n",
    "          activation: (optional) an optional activation function.\n",
    "          reuse: (optional) Python boolean describing whether to reuse variables\n",
    "            in an existing scope.  If not `True`, and the existing scope already has\n",
    "            the given variables, an error is raised.\n",
    "        Raises:\n",
    "          TypeError: if cell is not an RNNCell.\n",
    "          ValueError: if output_size is not positive.\n",
    "        \"\"\"\n",
    "        super(MyOutputProjectionWrapper, self).__init__(_reuse=reuse)\n",
    "        rnn_cell_impl.assert_like_rnncell(\"cell\", cell)\n",
    "        if output_size < 1:\n",
    "            raise ValueError(\n",
    "                \"Parameter output_size must be > 0: %d.\" % output_size)\n",
    "        self._cell = cell\n",
    "        self._output_size = output_size\n",
    "        self._activation = activation\n",
    "        self._W = W\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._cell.state_size\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._output_size\n",
    "\n",
    "    def zero_state(self, batch_size, dtype):\n",
    "        with ops.name_scope(type(self).__name__ + \"ZeroState\", values=[batch_size]):\n",
    "            return self._cell.zero_state(batch_size, dtype)\n",
    "\n",
    "    def call(self, inputs, state):\n",
    "        \"\"\"Run the cell and output projection on inputs, starting from state.\"\"\"\n",
    "        output, res_state = self._cell(inputs, state)\n",
    "        projected = tf.matmul(output, tf.transpose(self._W))\n",
    "        if self._activation:\n",
    "            projected = self._activation(projected)\n",
    "        return projected, res_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatModel:\n",
    "    def __init__(self, config_file, x_max_len, y_max_len, max_decode_len, vocab, ckpt_file=None):\n",
    "        self.x_max_len = x_max_len\n",
    "        self.y_max_len = y_max_len\n",
    "        self.vocab = vocab\n",
    "        self.beam_width = 4\n",
    "        self.max_decode_len = max_decode_len\n",
    "        self.x = tf.placeholder(tf.int32, shape=[None, self.x_max_len], name='x')\n",
    "        self.x_mask = tf.placeholder(tf.int32, shape=[None, self.x_max_len], name='x_mask')\n",
    "        self.x_seg = tf.placeholder(tf.int32, shape=[None, self.x_max_len], name='x_seg')\n",
    "        self.x_len = tf.placeholder(tf.int32, shape=[None], name='x_len')\n",
    "        self.y = tf.placeholder(tf.int32, shape=[None, self.y_max_len], name='y')\n",
    "        self.y_len = tf.placeholder(tf.int32, shape=[None], name='y_len')\n",
    "        self.bert_config = BertConfig.from_json_file(config_file)\n",
    "        self.hidden_size = self.bert_config.hidden_size\n",
    "        self.vocab_size = self.bert_config.vocab_size\n",
    "        self.bert_model = BertModel(config=self.bert_config, input_ids=self.x, input_mask=self.x_mask, token_type_ids=self.x_seg, is_training=True, use_one_hot_embeddings=False)\n",
    "        if ckpt_file is not None:\n",
    "            tvars = tf.trainable_variables()\n",
    "            self.assignment_map, self.initialized_variable_map = modeling.get_assignment_map_from_checkpoint(tvars, ckpt_file)\n",
    "        \n",
    "    def inference(self):\n",
    "        x = self.x\n",
    "        batch_size = tf.shape(self.x)[0]\n",
    "        X = self.bert_model.get_sequence_output()\n",
    "        self.embeddings = self.bert_model.get_embedding_table()\n",
    "        \n",
    "        start_tokens = tf.ones([batch_size], dtype=tf.int32) * tf.convert_to_tensor(self.vocab['<S>'])\n",
    "        train_output = tf.concat([tf.expand_dims(start_tokens, 1), self.y], 1)\n",
    "        output_emb = tf.nn.embedding_lookup(self.embeddings, train_output)\n",
    "        output_len = 1 + self.y_len\n",
    "        \n",
    "        encoder_output = X[:,1:,:]\n",
    "        encoder_state = X[:,0,:]\n",
    "        \n",
    "        train_helper = tf.contrib.seq2seq.ScheduledEmbeddingTrainingHelper(output_emb, output_len, self.embeddings, 0.1)\n",
    "        cell = tf.contrib.rnn.GRUCell(num_units=self.hidden_size)\n",
    "        \n",
    "        def decode(scope):\n",
    "            with tf.variable_scope(scope):\n",
    "                attention_mechnism = tf.contrib.seq2seq.BahdanauAttention(num_units=self.hidden_size, memory=encoder_output, memory_sequence_length=self.x_len)\n",
    "                attention_cell = tf.contrib.seq2seq.AttentionWrapper(cell, attention_mechnism, attention_layer_size=self.hidden_size)\n",
    "                out_cell = MyOutputProjectionWrapper(attention_cell, self.vocab_size, self.embeddings, reuse=False)\n",
    "                initial_state = out_cell.zero_state(dtype=tf.float32, batch_size=batch_size)\n",
    "                initial_state = initial_state.clone(cell_state=encoder_state)\n",
    "                decoder = tf.contrib.seq2seq.BasicDecoder(cell=out_cell, initial_state=initial_state, helper=train_helper)\n",
    "                t_final_output, t_final_state, t_final_seq_len = tf.contrib.seq2seq.dynamic_decode(decoder=decoder, impute_finished=True, output_time_major=False, maximum_iterations=self.max_decode_len)\n",
    "            with tf.variable_scope(scope, reuse=True):\n",
    "                tiled_encoder_output = tf.contrib.seq2seq.tile_batch(encoder_output, multiplier=self.beam_width)\n",
    "                tiled_encoder_state = tf.contrib.seq2seq.tile_batch(encoder_state, multiplier=self.beam_width)\n",
    "                tiled_x_len = tf.contrib.seq2seq.tile_batch(self.x_len, multiplier=self.beam_width)\n",
    "                attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(num_units=self.hidden_size, memory=tiled_encoder_output, memory_sequence_length=tiled_x_len)\n",
    "                attention_cell = tf.contrib.seq2seq.AttentionWrapper(cell, attention_mechanism=attention_mechnism, attention_layer_size=self.hidden_size)\n",
    "                out_cell = MyOutputProjectionWrapper(attention_cell, self.vocab_size, self.embeddings, reuse=True)\n",
    "                initial_state = out_cell.zero_state(dtype=tf.float32, batch_size=batch_size*self.beam_width)\n",
    "                initial_state = initial_state.clone(cell_state=tiled_encoder_state)\n",
    "                end_token = self.vocab['<T>']\n",
    "                decoder = tf.contrib.seq2seq.BeamSearchDecoder(cell=out_cell, beam_width=self.beam_width, coverage_penalty_weight=0.001, embedding=self.embeddings, initial_state=initial_state, start_tokens=start_tokens, end_token=end_token)\n",
    "                p_final_output, p_final_state, p_seq_len = tf.contrib.seq2seq.dynamic_decode(decoder=decoder, output_time_major=False, maximum_iterations=self.max_decode_len)\n",
    "            return t_final_output, p_final_output\n",
    "        t_output, p_output = decode('decode')\n",
    "        p_output = tf.identity(p_output.predicted_ids[:,:,0], name='predictions')\n",
    "        return t_output, p_output\n",
    "        \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = './model/chinese_L-12_H-768_A-12/vocab.txt'\n",
    "tokenizer = bert.tokenization.FullTokenizer(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = './model/chinese_L-12_H-768_A-12/bert_config.json'\n",
    "x_max_len = 100\n",
    "y_max_len = 50\n",
    "max_decode_len = 50\n",
    "ckpt_file = './model/chinese_L-12_H-768_A-12/bert_model.ckpt'\n",
    "chat_model = ChatModel(config_file, x_max_len, y_max_len, max_decode_len, tokenizer.vocab, ckpt_file)\n",
    "t_output, p_output = chat_model.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.convert_to_tensor(tokenizer.vocab['<T>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
